---
title: "Assignment 4"
author: "Santiago Rattenbach, Àngel Jiménez, Albert Salom"
date: "21/11/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Libraries, include=FALSE}
# Load the required libraries, without showing warning messages
suppressWarnings({
  suppressPackageStartupMessages({
    library(ggplot2)
    library(GGally)
  })
})
```

## The Data

```{r}
data <- read.csv("./penguindata.csv", header=TRUE, stringsAsFactors=TRUE)
str(data)
```

Si hacemos un primer vistazo, podemos observar como tenemos varios valores NAs que deberemos gestionar
posteriormente.

### Independent Variables

The dataset includes measurements taken for penguins in Palmer Archipelago. Variable information:
size (flipper length, body mass, bill dimensions), sex and year.

- **bill_length_mm:** a number denoting bill length (millimeters)
- **bill_depth_mm:** a number denoting bill depth (millimeters)
- **flipper_length_mm:** an integer denoting flipper length (millimeters)
- **body_mass_g:** an integer denoting body mass (grams)
- **sex:** a factor denoting penguin sex (female, male)
- **year:** an integer denoting the study year (2007, 2008, or 2009)

### Summary of the Data

Before start training the model, it is important to analyze each of the independent variables to understand
their values, distribution, and relationship with the target variable.

```{r}
summary(data)
```

Como podemos observar, tenemos varios valores NA en las variables bill_length_mm, bill_depth_mm, 
flipper_length_mm, body_mass_g y sex. Más tarde los trataremos.

#### Numerical Variables

- **bill_length_mm:** Este dataset contiene la longitud del pico de los pinguinos en milimetros. Vemos que 
  la longitud del pico de los pinguinos varia entre 32.1 y 59.6 milimetros, con una media de 44mm. No parece 
  haber nada alarmante

- **bill_depth_mm:**  La profundidad del pico de los picos también viene en milimetros, en un rango entre 
  13.1mm y 21.5mm, con una media de 17.2mm.

- **flipper_length_mm:** La longitud de las aletas de los pinguinos del dataset varia entre 172mm y 231mm, 
  con una media de 201mm. No parece haber ningun valor atípico.

- **body_mass_g:** En el dataset, podemos observar que el peso de los pinguinos puede variar bastante, esto 
  podría deberse a la edad de los pinguinos, ya que los pinguinos más jóvenes suelen pesar menos. El peso
  de los pinguinos varia entre 2700g y 6300g, con una media de 4202g.

```{r}
# List of numerical variables:
numeric <- c('bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g')

# Plot the distribution of each numerical variable:
for (n in numeric) {
  print(
    ggplot(data, aes(x = !!sym(n))) +
      geom_histogram(fill = "lightblue", color = "white", bins = 30) +
      labs(title = paste("Distribution of", n), x = n, y = "Frecuency") +
      theme_minimal()
  )
}
```

A primera vista, parece ser que las variables numericas están algo centradas, asemejandose a una distribución
normal. Igualmente, posteriormente realizaremos un análisis de normalidad para confirmar esto.

#### Categorical

```{r}
# List of categorical variables:
categories <- c('year', 'sex')

for (var in categories) {
  print(
    ggplot(data, aes_string(x = var)) +
      geom_bar(fill = "coral1") +
      labs(title = paste("Distribution of", var), x = var, y = "Frecuency") +
      theme_minimal()
  )
}
```

- **sex:** Se puede observar que hay una cantidad similar de pinguinos machos y hembras en el dataset. 
  Esto es importante ya que si hubiera una gran diferencia entre los dos sexos, podría afectar a la 
  precisión del modelo.

- **year:** En el dataset, podemos observar que en cada año se ha hecho el estudio a un número similar de 
  pingüinos. Nuevamente, esto nos beneficiará a la hora de entrenar el modelo.

### Missing Value Analysis

To find missing values in the dataset, we can use the `is.na()` function in R. 

```{r}
colSums(is.na(data))
```

Como se puede observar, tenemos varias columnas con valores NA. Al tratarse de pocos valores, podemos borrar 
tranquilamente sin que el modelo se vea afectado.

```{r}
data <- na.omit(data)
summary(data)
```

### Data Correlations

```{r}
ggpairs(data)
```

```{r}
ggpairs(data,                 # Data frame
        columns = 2:7,        # Columns
        aes(color = year,     # Color by grup (cathegorical)
            alpha = 0.5))     # Transparency
```

#### Numerical Variables

```{r}
numeric_Corr <- data[, c('bill_length_mm', 'bill_depth_mm', 'flipper_length_mm',
                        'body_mass_g')]

ggcorr(numeric_Corr, label = TRUE)
```
 
### Bivariate Analysis

#### Numeric Variables



#### Categorical Variables






### Key Features



### PreProcessing Data

#### Checking Normality (Skewness)

Now we will check the normality of the numerical variables to see if they follow a normal distribution.
In case they do not, we will apply transformations to make them follow a normal distribution.



#### Creation of a better skewed dataset



## Model Building

### Sorting Variables

To better handle the data, we find it convenient to reorder the columns, placing the numerical columns 
first, followed by the categorical ones, and finally the target variable.

```{r}
# Identify numeric and factor columns
numeric_columns <- sapply(data_Transformed, is.numeric)
factor_columns <- sapply(data_Transformed, is.factor)


# Order the columns: first the numeric ones, then the factor ones, and finally the target variable
ordered_columns <- c(names(data_Transformed)[numeric_columns], 
                     names(data_Transformed)[factor_columns])

# Reorder DataFrame
data_Transformed <- data_Transformed[, ordered_columns]
```

### Data Normalization

We ensure that all the numerical variables are normalized to the same scale, so that there isn't one with a
greater influence than the others.

```{r}
# Create normalization function
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Identify the numerical columns
numerical_columns <- sapply(data_Transformed, is.numeric)

# Apply a transformation (e.g., normalization) only to the numerical columns
data_Normalized <- data_Transformed
# Normalize the numerical data
data_Normalized[, numerical_columns] <- as.data.frame(lapply(data_Transformed[, numerical_columns], normalize))

# Confirm that normalization worked
summary(data_Normalized)
```

### Train-Test Split

Before splitting into train and test sets, it is important to know that, for k-Nearest Neighbors and Naive 
Bayes, all variables need to be numeric. For categorical variables, we use one-hot encoding to convert them 
into numeric variables, where each category becomes a new binary column.

```{r}
# Convert categorical variables into numerical ones with one-hot encoding
data_Normalized <- model.matrix(~ . - 1, data = data_Normalized)

# Convert the result to a data frame
data_Normalized <- as.data.frame(data_Normalized)
```

```{r}
## To reproduce the calculations
seeds <- c(1357, 2468, 3579)
set.seed(seeds[1])

## Create an index to partition the data set
ind <- sample(2, nrow(data_Normalized), replace=TRUE, prob=c(0.80, 0.20))

data_Normalized.train <- data_Normalized[ind==1,]
data_Normalized.test <- data_Normalized[ind==2,]
```

We have split the data into a training set and a test set, with 80% of the data in the training set and 20%
in the test set. Let's check that the partitions have been done correctly.

```{r}
nrow(data_Normalized)
nrow(data_Normalized.train)
nrow(data_Normalized.test)
```

## Classification using Nearest Neighbors

### Predictions



## Classification using Naive Bayes


## Classification using Decision Trees



### Conversion of Numerical Variables 



## Conclusion



### Testing different seeds of train/test



#### Seed 1

#### 0.8 Train - 0.2 Test



#### 0.7 Train - 0.3 Test



#### 0.9 Train - 0.1 Test



#### Seed 2



#### Seed 3



### Choosing the best model



### Our Learnings



### References

- [R Documentation] (https://www.rdocumentation.org/): Used to understand some of the functions and packages
  used in our analysis.
- [ChatGPT] (chatgpt.com): Used for help in making sense of the data, translation of some text originally
  written in Spanish and removal of certain warnings generated by library functions.
- [RMD files from class]: Used as a reference for the structure of the document and as examples of
  model implementation.
